{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Spark Session Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import datetime\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "# from pyspark import SparkContext, SQLContext, SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import os\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "      .appName(\"Word count\") \\\n",
    "      .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.0612494945526123 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "game_id='945360' # sample game id given here, refer steam website for appropriate game id\n",
    "qwe=requests.get('https://store.steampowered.com/appreviewhistogram/'+game_id).content\n",
    "ress = json.loads(qwe.decode(\"utf-8\")) \n",
    "date_rec=[]\n",
    "up_rec=[]\n",
    "down_rec=[]\n",
    "date_roll=[]\n",
    "up_roll=[]\n",
    "down_roll=[]\n",
    "for i in ress['results']['recent']:\n",
    "    date_rec.append(i['date'])\n",
    "    up_rec.append(i['recommendations_up'])\n",
    "    down_rec.append(i['recommendations_down'])\n",
    "for i in ress['results']['rollups']:\n",
    "    date_roll.append(i['date'])\n",
    "    up_roll.append(i['recommendations_up'])\n",
    "    down_roll.append(i['recommendations_down'])\n",
    "    \n",
    "    \n",
    "rec_up_dataa = pd.DataFrame(list(zip(date_rec, up_rec)), \n",
    "               columns =['date', 'up']) \n",
    "rec_down_dataa = pd.DataFrame(list(zip(date_rec, down_rec)), \n",
    "               columns =['date', 'up']) \n",
    "roll_up_dataa = pd.DataFrame(list(zip(date_roll, up_roll)), \n",
    "               columns =['date', 'up']) \n",
    "roll_down_dataa = pd.DataFrame(list(zip(date_roll, down_roll)), \n",
    "               columns =['date', 'up']) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Relevant Data from MongoDB Atlas Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Among Us'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "client = MongoClient(\"MongoDB Collection URL Here\") # Collection URL Not specified for Data Security\n",
    "db = client.get_database('steam_data')\n",
    "coll=db.game_data\n",
    "cur=coll.find_one({\"url_info.id\":game_id},{\"name\":1})\n",
    "game_name=cur['name']\n",
    "print(game_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Decision Tree Regression Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_plot(spark, dfname):\n",
    "    data = spark.createDataFrame(dfname)\n",
    "    data2 =data.select(data.date,data.up.alias('label'))\n",
    "    train=data2\n",
    "    test=data2\n",
    "    assembler=VectorAssembler().setInputCols(['date',]).setOutputCol('features')\n",
    "    train01 = assembler.transform(train)\n",
    "    train02 = train01.select(\"features\",\"label\")\n",
    "    lr = LinearRegression()\n",
    "    model = lr.fit(train02)\n",
    "    test01 = assembler.transform(test)\n",
    "    test02 = test01.select('features', 'label')\n",
    "    test03 = model.transform(test02)\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(test02)\n",
    "\n",
    "    trainingData=test02\n",
    "    testData=test02\n",
    "    dt = DecisionTreeRegressor(maxDepth=2,featuresCol=\"indexedFeatures\")\n",
    "    pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "    model = pipeline.fit(trainingData)\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"RMSE on test data = %g\" % rmse)\n",
    "    pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "    model = pipeline.fit(test02)\n",
    "    predictions = model.transform(test02)\n",
    "    p1 = go.Scatter(x=[datetime.datetime.fromtimestamp(i.__getitem__(\"date\")) for i in data.select(col(\"date\")).collect()],\n",
    "                    y=list(data.select('up').toPandas()['up']), \n",
    "                    mode='markers',\n",
    "                    marker=dict(size=6,color='darkorange',line=dict(width=2,color='DarkSlateGrey')),\n",
    "                    name=\"Data\")\n",
    "\n",
    "    p2 = go.Scatter(x=[datetime.datetime.fromtimestamp(i.__getitem__(\"date\")) for i in data.select(col(\"date\")).collect()],\n",
    "                    y=list(predictions.select('prediction').toPandas()['prediction']), \n",
    "                    mode='lines',\n",
    "                    line=dict(color=\"cornflowerblue\"),\n",
    "                    name=\"DTR Predicted\")\n",
    "    p3= go.Scatter(\n",
    "            x=[datetime.datetime.fromtimestamp(i.__getitem__(\"date\")) for i in data.select(col(\"date\")).collect()],\n",
    "            y=list(test03.select('prediction').toPandas()['prediction']),\n",
    "            mode='lines',\n",
    "            line=dict(color=\"yellowgreen\"),\n",
    "            name='LR Predicted'\n",
    "        )\n",
    "    fig = go.Figure(data=[p1, p2, p3])\n",
    "    return([fig, p1, p2, p3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_lin_reg(spark, df_list, game_name, final_file_name):\n",
    "    plot4=lin_reg_plot(spark, df_list[0])\n",
    "    plot3=lin_reg_plot(spark, df_list[1])\n",
    "    plot2=lin_reg_plot(spark, df_list[2])\n",
    "    plot1=lin_reg_plot(spark, df_list[3])\n",
    "    fig = plotly.subplots.make_subplots(rows=2,cols=2, subplot_titles= ['All-Time Positive reviews',\n",
    "                                                                  'All-Time Negative reviews',\n",
    "                                                                  'Recent Positive reviews',\n",
    "                                                                  'Recent Negative reviews'])\n",
    "    fig.append_trace(plot1[1],1,1)\n",
    "    fig.append_trace(plot1[2],1,1)\n",
    "    fig.append_trace(plot1[3],1,1)\n",
    "    fig.append_trace(plot2[1],1,2)\n",
    "    fig.append_trace(plot2[2],1,2)\n",
    "    fig.append_trace(plot2[3],1,2)\n",
    "    fig.append_trace(plot3[1],2,1)\n",
    "    fig.append_trace(plot3[2],2,1)\n",
    "    fig.append_trace(plot3[3],2,1)\n",
    "    fig.append_trace(plot4[1],2,2)\n",
    "    fig.append_trace(plot4[2],2,2)\n",
    "    fig.append_trace(plot4[3],2,2)\n",
    "    fig.update_layout(title_text=game_name, template=\"plotly_dark\")\n",
    "    fig.write_html(final_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step\n",
    "    - plotting and opening plot in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 6018.77\n",
      "Root Mean Squared Error (RMSE) on test data = 407.034\n",
      "Root Mean Squared Error (RMSE) on test data = 980.181\n",
      "Root Mean Squared Error (RMSE) on test data = 24.6779\n"
     ]
    }
   ],
   "source": [
    "df_list=[roll_up_dataa, roll_down_dataa, rec_up_dataa, rec_down_dataa]\n",
    "final_lin_reg(spark, df_list, game_name+' User Trend Analysis', \"final_regression.html\")\n",
    "webbrowser.open('file://' + os.path.realpath('final_regression.html'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
