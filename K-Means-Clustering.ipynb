{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SQLContext\n",
    "import plotly.express as px\n",
    "from pyspark.sql import SparkSession\n",
    "# from plotly.graph_objs import Scene\n",
    "import numpy as np\n",
    "from kneed import KneeLocator\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "# import traceback\n",
    "from scipy import stats\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import os\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "      .appName(\"Word count\") \\\n",
    "      .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data from MongoDB Atlas Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 49.3672251701355 seconds ---\n"
     ]
    }
   ],
   "source": [
    "em_list=[]\n",
    "start_time = time.time()\n",
    "client = MongoClient(\"MongoDB Collection URL Here\") # Collection URL Not specified for Data Security\n",
    "db = client.get_database('steam_data')\n",
    "game_id=\"271590\" # get game id here sample game id : 271590 has been specified\n",
    "coll=db.game_data\n",
    "cur=coll.find_one({\"url_info.id\":game_id},{\"popu_tags\":1})\n",
    "tags=[]\n",
    "tag_length=len(cur[\"popu_tags\"])\n",
    "for i in cur[\"popu_tags\"]:\n",
    "    tags.append(i)\n",
    "    cur=coll.find({\"popu_tags\":{\"$in\":[i]}},{\"url_info.id\":1,\"name\":1,'price':1})#,\"popu_tags\":1, \"_id\":1})\n",
    "    cur=[i for i in cur]\n",
    "    if(tag_length>15):\n",
    "        cur=cur[:tag_length]\n",
    "    else:\n",
    "        cur=cur[:20]\n",
    "    em_list=em_list+cur\n",
    "em_list=list({v['name']:v for v in em_list}.values())\n",
    "em_list=em_list[:200]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Deletion Implementation\n",
    "    - Any data which is 3 days old will be automatically deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Cache Deletion Implementation\n",
    "\n",
    "def old_data_clearance(db):\n",
    "    now = datetime.now()\n",
    "    game_review_data=db.game_review_data.find({\n",
    "\n",
    "    },{\n",
    "       \"game_id\": 1,\n",
    "       \"epoch\": 1\n",
    "    }\n",
    "    );\n",
    "\n",
    "    game_review_data=[i for i in game_review_data]\n",
    "\n",
    "    for i in game_review_data:\n",
    "        if((int(i['epoch'])-int(time.mktime(now.timetuple())))>259200):\n",
    "            db.game_review_data.find({\"game_id \" :  i['game_id']},{\"E\": 1});\n",
    "            print(str(i['game_id'])+' Deleted')\n",
    "\n",
    "old_data_clearance(client.get_database('steam_data'))    \n",
    "\n",
    "############ Cache Deletion Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "import pandas as pd\n",
    "name=[]\n",
    "price=[]\n",
    "pos_rev=[]\n",
    "neg_rev=[]\n",
    "l1=em_list\n",
    "for i in l1:\n",
    "    try:\n",
    "            name.append(i['name'])\n",
    "            if(i['price']!='free'):\n",
    "                try:\n",
    "                    price.append(int(i['price']))\n",
    "                except:\n",
    "                    print(i['price'])\n",
    "                    price.append(0)\n",
    "            else:\n",
    "                price.append(0)\n",
    "            ress=db.game_review_data.find_one({'game_id':str(i['url_info']['id'])})\n",
    "            if(type(ress)!=type(dict())):\n",
    "                qwe=requests.get('https://store.steampowered.com/appreviews/'+str(i['url_info']['id'])+'?json=1').content\n",
    "                ress = json.loads(qwe.decode(\"utf-8\"))\n",
    "                ress['game_id']=str(i['url_info']['id'])\n",
    "                now = datetime.now()\n",
    "                ress['epoch']=int(time.mktime(now.timetuple()))\n",
    "                db.game_review_data.insert_one(ress)\n",
    "                print(str(ress['game_id'])+' Inserted')\n",
    "            else:\n",
    "                print(str(ress['game_id'])+' fetched')\n",
    "            pos_rev.append(ress['query_summary']['total_positive'])\n",
    "            neg_rev.append(ress['query_summary']['total_negative'])\n",
    "    except:\n",
    "#         print(str(traceback.format_exc()))\n",
    "#         print(i)\n",
    "        pass\n",
    "        \n",
    "df = pd.DataFrame(list(zip(name, price, pos_rev, neg_rev)), \n",
    "               columns =['Name', 'Price','Positive_Reviews','Negative_Reviews']) \n",
    "for i in df.columns:\n",
    "    try:\n",
    "        df=df[list(np.abs(stats.zscore(list(df[i]))) < 3)]\n",
    "    except:\n",
    "        pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Function\n",
    "    - Dynamic Determination of Appropriate number of Clusters using Elbow Method has been implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_3dplot(spark, df, op_html):\n",
    "    sqlContext = SQLContext(spark)\n",
    "    FEATURES_COL = ['Price', 'Positive_Reviews', 'Negative_Reviews']\n",
    "    df = spark.createDataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in FEATURES_COL:\n",
    "            df = df.withColumn(col,df[col].cast('float'))\n",
    "    df = df.na.drop()\n",
    "    vecAssembler = VectorAssembler(inputCols=FEATURES_COL, outputCol=\"features\")\n",
    "    df_kmeans = vecAssembler.transform(df).select('Name', 'features')\n",
    "    cost = np.zeros(20)\n",
    "    for k in range(2,20):\n",
    "        kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
    "        model = kmeans.fit(df_kmeans.sample(False,0.1, seed=42))\n",
    "        cost[k] = model.summary.trainingCost\n",
    "    y=cost[2:20]\n",
    "    x = range(1, len(y)+1)\n",
    "    kn = KneeLocator(x, y, curve='convex', direction='decreasing')\n",
    "    try:\n",
    "        k = int(kn.knee)\n",
    "    except:\n",
    "        k=2\n",
    "    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
    "    model = kmeans.fit(df_kmeans)\n",
    "    transformed = model.transform(df_kmeans).select('Name', 'prediction')\n",
    "    rows = transformed.collect()\n",
    "    df_pred = sqlContext.createDataFrame(rows)\n",
    "    df_pred = df_pred.join(df, 'Name')\n",
    "    pddf_pred = df_pred.toPandas().set_index('Name')\n",
    "    fig = px.scatter_3d(x=pddf_pred.Price, \n",
    "                        y=pddf_pred.Positive_Reviews, \n",
    "                        z=pddf_pred.Negative_Reviews, \n",
    "                        color=pddf_pred.prediction,  \n",
    "                        hover_name=list(df.select('Name').toPandas()['Name']))\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='Price',\n",
    "                    yaxis_title='Positive Reviews',\n",
    "                    zaxis_title='Negative Reviews'), template=\"plotly_dark\")\n",
    "    fig.write_html(op_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step\n",
    "    - Plotting 3d Clustering Plot and opening it in Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_3dplot(spark, df,'kmeans_cache testt.html')\n",
    "webbrowser.open('file://' + os.path.realpath('kmeans_plot.html'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
